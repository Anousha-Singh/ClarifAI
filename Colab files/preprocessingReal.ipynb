{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNvDQbO+Wcz5cp2TjewEujd"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lHd-sG2InyzW","executionInfo":{"status":"ok","timestamp":1740227386190,"user_tz":-330,"elapsed":21280,"user":{"displayName":"Anousha","userId":"04476830509364725369"}},"outputId":"4ae65575-5aa8-47fa-8ef4-4d46500a71e2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import gdown\n","\n","# File url\n","file_id = \"1TbnATpxdtC7SECCMVab4OaO3u-Y0cz9F\"\n","url = f\"https://drive.google.com/uc?id={file_id}\"\n","\n","gdown.download(url, \"real.zip\", quiet=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":122},"id":"NRyhihamn7hn","executionInfo":{"status":"ok","timestamp":1740227411286,"user_tz":-330,"elapsed":23208,"user":{"displayName":"Anousha","userId":"04476830509364725369"}},"outputId":"1416a8e9-0b84-4af4-f0b2-39ad81927e1c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading...\n","From (original): https://drive.google.com/uc?id=1TbnATpxdtC7SECCMVab4OaO3u-Y0cz9F\n","From (redirected): https://drive.google.com/uc?id=1TbnATpxdtC7SECCMVab4OaO3u-Y0cz9F&confirm=t&uuid=6b661ddc-18ad-4f27-9c2c-142c6dae5596\n","To: /content/real.zip\n","100%|██████████| 1.61G/1.61G [00:18<00:00, 85.9MB/s]\n"]},{"output_type":"execute_result","data":{"text/plain":["'real.zip'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["import os\n","import zipfile\n","extract_path = \"/content/extracted_real\"\n","\n","# Create directory if it does not exist\n","if not os.path.exists(extract_path):\n","    os.makedirs(extract_path)\n","\n","# Extract the zip file\n","with zipfile.ZipFile(\"real.zip\", \"r\") as zip_ref:\n","    zip_ref.extractall(extract_path)\n","\n","print(\"Extraction complete! Files are in:\", extract_path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dZa0yRIAoKtr","executionInfo":{"status":"ok","timestamp":1740227434193,"user_tz":-330,"elapsed":16362,"user":{"displayName":"Anousha","userId":"04476830509364725369"}},"outputId":"c95b3f97-722b-4be0-f05f-201fda77d470"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Extraction complete! Files are in: /content/extracted_real\n"]}]},{"cell_type":"code","source":["import glob\n","import numpy as np\n","import cv2\n","import copy\n","\n","video_files =  glob.glob('/content/extracted_real/*.mp4')\n","\n","frame_count = []\n","for video_file in video_files:\n","\n","  cap = cv2.VideoCapture(video_file)   # Opens the video file\n","\n","  # Skip videos that have frames less than 150\n","  if(int(cap.get(cv2.CAP_PROP_FRAME_COUNT))<150):\n","    video_files.remove(video_file)\n","    continue\n","\n","  frame_count.append(int(cap.get(cv2.CAP_PROP_FRAME_COUNT)))   # Frame count\n","\n","print(\"Frames:\" , frame_count)\n","print(\"Total number of videos: \" , len(frame_count))\n","print('Average frame per video:',np.mean(frame_count))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TXwfVoBOoQtu","executionInfo":{"status":"ok","timestamp":1740227438154,"user_tz":-330,"elapsed":817,"user":{"displayName":"Anousha","userId":"04476830509364725369"}},"outputId":"2e8f346a-c373-4164-a183-5a4736aa3b5e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Frames: [323, 319, 460, 450, 437, 331, 491, 326, 397, 514, 450, 332, 250, 472, 481, 297, 460, 479, 282, 368, 463, 317, 345, 332, 570, 339, 505, 416, 235, 464, 314, 317, 391, 289, 434, 473, 321, 332, 463, 310, 488, 389, 295, 468, 449, 269, 451, 469, 413, 416, 527, 459, 457, 462, 484, 447, 315, 459, 417, 303, 582, 422, 477, 410, 272, 429, 315, 471, 461, 467, 468, 495, 473, 315, 172, 483, 447, 335, 404, 398, 555, 209, 335, 458, 450, 373, 492, 499, 379, 428, 433, 429, 459, 421, 448, 399, 466, 318, 319, 323, 467, 490, 483, 342, 493, 463, 422, 468, 318, 321, 340, 585, 445, 320, 361, 478, 469, 331, 468, 452, 459, 325, 335, 464, 470, 454, 417, 502, 383, 380, 317, 319, 510, 445, 526, 199, 497, 489, 455, 464, 466, 530, 353, 469, 516, 455, 494, 318, 461, 455, 477, 478, 316, 573, 376, 547, 534, 332, 448, 310, 470, 494, 571, 553, 492, 330, 327, 442, 337, 312, 310, 477, 478, 456, 321, 460, 432, 541, 485, 349, 460, 322, 387, 338, 410, 453, 472, 467, 308, 478, 512, 490, 477, 461, 328, 520, 420, 448, 466, 485, 519, 309, 467, 468, 422, 473, 362, 386, 474, 470, 342, 464, 516, 330, 477, 273, 456, 329, 369, 504, 375, 463, 551, 462, 322, 305, 471, 316, 446, 478, 307, 400, 455, 418, 256, 322, 466, 341, 463, 225, 495, 455, 414, 350, 475, 514, 327, 365, 639, 457, 442, 266, 471, 460, 475, 376, 239, 314, 459, 450, 478, 350, 611, 332, 322, 464, 505, 357, 381, 365, 432, 326, 504, 370, 317, 492, 332, 458, 480, 462, 474, 264, 320, 315, 283, 323, 325, 470, 468, 353, 335, 464, 347, 322, 321, 465, 316, 468, 479, 313, 454, 336, 477, 456, 450, 332, 228, 313, 449, 312, 249, 478, 351, 320, 459, 224, 306, 499, 475, 307, 359, 390, 415, 412, 310, 338, 468, 338, 324, 305, 334, 722, 469, 363, 327, 295, 409, 316, 398, 480, 557, 517, 284, 311, 364, 473, 321, 474, 315, 479, 383, 299, 458, 391, 373, 478, 485, 328, 332, 313, 319, 316, 305, 342, 477, 303, 470, 501, 479, 458, 435, 510, 466, 372, 477, 371, 314, 344, 376, 311, 270, 333, 563, 451, 266, 464, 342, 298, 333, 342, 450, 483, 458, 451, 243, 419, 307, 465, 502, 323, 455, 291, 365, 454, 292, 456, 267, 329, 478, 469, 280, 333, 237, 458, 215, 445, 252, 465, 308, 482, 467, 307, 584, 315, 311, 330, 474, 441, 357, 534, 504, 516, 355, 493, 302, 349, 322, 286, 186, 449, 462, 571, 499, 307, 307, 605, 446, 461, 353, 342, 349, 324, 295, 383, 372, 201, 334, 331, 334, 476, 319, 317, 474, 506, 503, 450, 315, 483, 475, 455, 447, 474, 499, 494, 314, 276, 458, 261, 333, 459, 427, 309, 474, 487, 462, 474, 479, 400, 449, 383, 452, 310, 487, 332, 445, 439, 451, 461, 316, 459, 466, 331, 335, 380, 465, 451, 467, 441, 412, 337, 470, 483, 330, 398, 457, 311, 466, 471, 334, 336, 327, 274, 350, 257, 280, 535, 290, 499, 283, 448, 456, 516, 453, 338, 459, 463, 313, 451, 350, 698, 322, 441, 333, 420, 313, 501, 476, 315, 319, 247, 460, 315, 462, 317, 579, 362, 425, 388, 455, 444, 293, 470, 468, 497, 334, 314, 315, 451, 304, 465, 436, 453, 323, 362, 513, 740, 401, 309, 306, 463, 341, 308, 467, 321, 380, 549, 474, 510, 449, 462, 534, 456, 352, 461, 259, 301, 481, 262, 459, 534, 474, 525, 340, 353, 311, 328, 437, 384, 306, 474, 459, 463, 480, 566, 480, 319, 313, 328, 319, 469, 328, 337, 442, 366, 322, 529, 464, 405, 423, 315, 338, 494, 317, 457, 476, 331, 499, 461, 317, 326, 468, 504, 458, 409, 321, 499, 533, 446, 478, 291, 324, 502, 234, 380, 394, 324, 319, 462, 468, 408, 317, 314, 295, 341, 471, 476, 363, 486, 492, 415, 303, 314, 325, 372, 448, 471, 383, 468, 301, 333, 610, 292, 382, 517, 480, 470, 460, 161, 448, 364, 377, 401, 380, 319, 456, 467, 458, 214, 467, 329, 359, 306, 481, 334, 278, 455, 381, 508, 348, 461, 308, 470, 493, 496, 294, 435, 428, 309, 347, 451, 325, 449, 308, 318, 310, 442, 310, 438, 461, 367, 438, 335, 461, 327, 363, 424, 352, 467, 408, 295, 447, 451, 230, 323, 320, 327, 288, 425, 472, 364, 469, 310, 331, 454, 504, 317, 306, 462, 611, 468, 471, 267, 463, 320, 481, 507, 312, 428, 371, 472, 446, 508, 315, 306, 312, 523, 349, 453, 312, 519, 489, 311, 261, 310, 455, 424, 313, 317, 479, 447, 475, 340, 470, 335, 357, 319, 333, 307, 327, 457, 464, 462, 310, 178, 462, 388, 354, 468, 483, 464, 411, 308, 337, 323, 455, 472, 468, 327, 457, 473, 319, 473, 431, 456, 339, 165, 461, 658, 305, 378, 477, 497, 326, 575, 521, 394, 550, 321, 468, 315, 312, 309, 414, 630, 447, 489, 451, 482, 467, 448, 467, 494, 338, 327, 334, 461, 467, 351, 334, 479, 283, 441, 466, 329, 440, 397, 311, 452, 459, 457, 280, 485, 301, 314, 314, 470, 380, 427, 322, 472]\n","Total number of videos:  880\n","Average frame per video: 403.7875\n"]}]},{"cell_type":"code","source":["# to extract frame\n","def frame_extract(path):\n","  vidObj = cv2.VideoCapture(path)\n","  success = 1\n","  while success:\n","      success, image = vidObj.read()\n","      if success:\n","          yield image  # Returns frame"],"metadata":{"id":"ldJVBt-zoUh4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install face_recognition\n","!mkdir '/content/drive/My Drive/preprocessedDataset'\n","!mkdir '/content/drive/My Drive/preprocessedDataset/real'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VVdIsR9doWl5","executionInfo":{"status":"ok","timestamp":1740460891442,"user_tz":-330,"elapsed":28948,"user":{"displayName":"Anousha","userId":"04476830509364725369"}},"outputId":"1ac339a3-9651-458f-f416-6ee63568e70f"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting face_recognition\n","  Downloading face_recognition-1.3.0-py2.py3-none-any.whl.metadata (21 kB)\n","Collecting face-recognition-models>=0.3.0 (from face_recognition)\n","  Downloading face_recognition_models-0.3.0.tar.gz (100.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.1/100.1 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.11/dist-packages (from face_recognition) (8.1.8)\n","Requirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.11/dist-packages (from face_recognition) (19.24.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from face_recognition) (1.26.4)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from face_recognition) (11.1.0)\n","Downloading face_recognition-1.3.0-py2.py3-none-any.whl (15 kB)\n","Building wheels for collected packages: face-recognition-models\n","  Building wheel for face-recognition-models (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for face-recognition-models: filename=face_recognition_models-0.3.0-py2.py3-none-any.whl size=100566162 sha256=67ed2c6f3055e732d476974dd24328f5ab785635693c01a8798f984398e16c30\n","  Stored in directory: /root/.cache/pip/wheels/04/52/ec/9355da79c29f160b038a20c784db2803c2f9fa2c8a462c176a\n","Successfully built face-recognition-models\n","Installing collected packages: face-recognition-models, face_recognition\n","Successfully installed face-recognition-models-0.3.0 face_recognition-1.3.0\n","mkdir: cannot create directory ‘/content/drive/My Drive/preprocessedDataset’: No such file or directory\n","mkdir: cannot create directory ‘/content/drive/My Drive/preprocessedDataset/real’: No such file or directory\n"]}]},{"cell_type":"code","source":["import torch\n","import torchvision\n","from torchvision import transforms\n","from torch.utils.data import DataLoader\n","from torch.utils.data.dataset import Dataset\n","import os\n","import numpy as np\n","import cv2\n","import matplotlib.pyplot as plt\n","import face_recognition\n","from tqdm import tqdm\n","\n","# process the frames\n","def create_face_videos(path_list,out_dir):\n","\n","  # No. of video already preprocessed\n","  already_present_count = glob.glob(os.path.join(out_dir, '*.mp4'))\n","\n","  print(\"No of videos already present \" , len(already_present_count))\n","\n","  # Skip already preprocessed videos\n","  for path in tqdm(path_list):\n","    out_path = os.path.join(out_dir,path.split('/')[-1])\n","    file_exists = glob.glob(out_path)\n","\n","    if(len(file_exists) != 0):\n","      print(\"File Already exists: \" , out_path)\n","      continue\n","\n","    frames = []\n","    flag = 0\n","    face_all = []\n","    frames1 = []\n","\n","    # Video writer object to convert frames to video\n","    out = cv2.VideoWriter(out_path,cv2.VideoWriter_fourcc('M','J','P','G'), 30, (112,112))\n","\n","    for idx,frame in enumerate(frame_extract(path)):\n","      if(idx <= 150):\n","        frames.append(frame)\n","        if(len(frames) == 4):\n","          faces = face_recognition.face_locations(frame, model='hog')\n","\n","          for i,face in enumerate(faces):\n","            if face:\n","              top,right,bottom,left = face\n","            try:\n","              out.write(cv2.resize(frames[i][top:bottom,left:right,:],(112,112)))\n","            except:\n","              pass\n","\n","          frames = []\n","    try:\n","      del top,right,bottom,left\n","    except:\n","      pass\n","\n","    out.release()\n","\n","print(\"Data preprocessed!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2lS_6KLIoZcq","executionInfo":{"status":"ok","timestamp":1740460899106,"user_tz":-330,"elapsed":4431,"user":{"displayName":"Anousha","userId":"04476830509364725369"}},"outputId":"5087415e-9de3-406f-b171-3ba13774aea2"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Data preprocessed!\n"]}]},{"cell_type":"code","source":["create_face_videos(video_files,'/content/drive/My Drive/preprocessedDataset/real')"],"metadata":{"id":"no65DDJBod6v"},"execution_count":null,"outputs":[]}]}