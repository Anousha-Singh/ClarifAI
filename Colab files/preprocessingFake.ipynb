{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOsSHYF67a2cEQj86j70lpr"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9yW6ayZIFjvK","executionInfo":{"status":"ok","timestamp":1740286120402,"user_tz":-330,"elapsed":33538,"user":{"displayName":"Anousha","userId":"04476830509364725369"}},"outputId":"2d2822ef-1a40-452f-d9f7-c4b24b2b31ee"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')     # Allows drive access to colab"]},{"cell_type":"code","source":["import gdown\n","\n","# File url\n","file_id = \"1HF6fB6_780fyNv5Tlxz0z_3V-A8p-aXP\"\n","url = f\"https://drive.google.com/uc?id={file_id}\"\n","\n","gdown.download(url, \"fake.zip\", quiet=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":125},"id":"Tb2HzCoiIjfj","executionInfo":{"status":"ok","timestamp":1740286150620,"user_tz":-330,"elapsed":24453,"user":{"displayName":"Anousha","userId":"04476830509364725369"}},"outputId":"9aa9115e-5280-438c-bf4c-114b9250205f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading...\n","From (original): https://drive.google.com/uc?id=1HF6fB6_780fyNv5Tlxz0z_3V-A8p-aXP\n","From (redirected): https://drive.google.com/uc?id=1HF6fB6_780fyNv5Tlxz0z_3V-A8p-aXP&confirm=t&uuid=6ab4e6a1-4a0f-484f-beca-8dbe72ff5530\n","To: /content/fake.zip\n","100%|██████████| 1.45G/1.45G [00:19<00:00, 74.1MB/s]\n"]},{"output_type":"execute_result","data":{"text/plain":["'fake.zip'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["import os\n","import zipfile\n","extract_path = \"/content/extracted_fake\"\n","\n","# Create directory if it does not exist\n","if not os.path.exists(extract_path):\n","    os.makedirs(extract_path)\n","\n","# Extract the zip file\n","with zipfile.ZipFile(\"fake.zip\", \"r\") as zip_ref:\n","    zip_ref.extractall(extract_path)\n","\n","print(\"Extraction complete! Files are in:\", extract_path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cre8kQxOdsWO","executionInfo":{"status":"ok","timestamp":1740212901785,"user_tz":-330,"elapsed":11550,"user":{"displayName":"Anousha","userId":"04476830509364725369"}},"outputId":"390f7478-a6d2-4521-c8a5-87ed44252b40"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Extraction complete! Files are in: /content/extracted_fake\n"]}]},{"cell_type":"code","source":["import glob\n","import numpy as np\n","import cv2\n","import copy\n","\n","video_files =  glob.glob('/content/extracted_fake/*.mp4')\n","\n","frame_count = []\n","for video_file in video_files:\n","\n","  cap = cv2.VideoCapture(video_file)   # Opens the video file\n","\n","  # Skip videos that have frames less than 150\n","  if(int(cap.get(cv2.CAP_PROP_FRAME_COUNT))<150):\n","    video_files.remove(video_file)\n","    continue\n","\n","  frame_count.append(int(cap.get(cv2.CAP_PROP_FRAME_COUNT)))   # Frame count\n","\n","print(\"Frames:\" , frame_count)\n","print(\"Total number of videos: \" , len(frame_count))\n","print('Average frame per video:',np.mean(frame_count))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s5uCI8IqdK2i","executionInfo":{"status":"ok","timestamp":1740212902568,"user_tz":-330,"elapsed":786,"user":{"displayName":"Anousha","userId":"04476830509364725369"}},"outputId":"a4e366a8-012b-40e4-f183-02f7349211f9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Frames: [365, 478, 302, 445, 467, 611, 520, 307, 328, 322, 557, 409, 557, 400, 505, 446, 442, 530, 365, 491, 611, 322, 459, 470, 499, 497, 361, 365, 372, 428, 534, 422, 630, 412, 428, 505, 530, 491, 365, 409, 376, 422, 467, 361, 483, 611, 272, 376, 469, 499, 497, 272, 477, 412, 630, 294, 380, 520, 506, 483, 381, 303, 439, 459, 398, 376, 380, 557, 470, 409, 412, 398, 530, 380, 425, 458, 409, 458, 428, 372, 458, 520, 483, 326, 409, 497, 380, 491, 302, 302, 328, 529, 376, 328, 470, 326, 380, 611, 557, 505, 516, 372, 442, 611, 459, 445, 272, 381, 323, 303, 458, 294, 272, 322, 529, 322, 740, 372, 412, 529, 422, 516, 412, 303, 439, 505, 376, 307, 491, 372, 303, 464, 372, 483, 458, 383, 491, 470, 479, 439, 470, 557, 369, 459, 383, 400, 398, 425, 516, 409, 350, 294, 323, 326, 326, 323, 458, 380, 294, 372, 409, 469, 398, 499, 479, 529, 483, 445, 439, 458, 470, 294, 372, 400, 458, 516, 479, 380, 361, 323, 516, 491, 478, 442, 372, 412, 400, 458, 458, 303, 446, 520, 557, 499, 302, 422, 425, 400, 412, 439, 505, 442, 445, 409, 611, 307, 381, 294, 497, 303, 459, 467, 400, 383, 372, 470, 459, 469, 470, 409, 505, 442, 409, 505, 376, 411, 520, 425, 302, 409, 400, 294, 530, 372, 350, 365, 451, 409, 295, 458, 350, 483, 409, 530, 469, 422, 272, 477, 470, 442, 458, 376, 272, 381, 557, 365, 477, 557, 425, 530, 516, 380, 534, 409, 409, 464, 529, 398, 483, 412, 464, 630, 557, 422, 422, 280, 328, 323, 361, 497, 409, 459, 425, 491, 376, 412, 350, 459, 380, 425, 458, 381, 323, 303, 307, 530, 499, 372, 326, 412, 361, 611, 372, 323, 398, 322, 372, 328, 383, 446, 326, 499, 380, 428, 491, 307, 409, 326, 380, 428, 442, 326, 380, 398, 499, 409, 412, 307, 326, 458, 464, 534, 409, 534, 372, 380, 479, 516, 380, 380, 458, 303, 372, 530, 529, 326, 272, 398, 469, 451, 328, 326, 412, 361, 483, 361, 497, 516, 459, 381, 323, 411, 467, 479, 303, 469, 439, 557, 483, 584, 467, 529, 328, 302, 376, 529, 428, 323, 458, 458, 479, 530, 422, 458, 328, 458, 302, 380, 326, 458, 365, 499, 302, 459, 322, 491, 422, 499, 381, 365, 459, 328, 412, 445, 520, 361, 467, 381, 365, 326, 458, 322, 477, 322, 428, 323, 428, 439, 491, 630, 328, 372, 497, 409, 294, 458, 428, 439, 409, 294, 272, 328, 415, 350, 307, 425, 380, 520, 442, 479, 497, 326, 326, 398, 409, 442, 372, 409, 350, 446, 303, 383, 361, 303, 442, 381, 451, 534, 161, 505, 409, 422, 451, 361, 483, 516, 451, 372, 451, 322, 451, 445, 326, 302, 439, 520, 557, 376, 451, 479, 630, 499, 323, 630, 409, 409, 459, 372, 372, 383, 458, 428, 328, 477, 497, 534, 442, 445, 477, 516, 459, 477, 467, 491, 412, 372, 520, 534, 478, 294, 380, 458, 477, 361, 451, 439, 458, 470, 361, 400, 458, 458, 294, 383, 516, 365, 326, 469, 458, 446, 479, 534, 294, 499, 467, 398, 459, 458, 272, 383, 530, 323, 302, 479, 380, 505, 497, 451, 557, 520, 458, 322, 428, 439, 350, 350, 380, 497, 411, 467, 322, 584, 740, 483, 497, 376, 400, 380, 380, 534, 469, 446, 459, 372, 302, 439, 307, 469, 383, 381, 497, 307, 380, 326, 497, 380, 372, 451, 322, 459, 307, 630, 381, 439, 451, 611, 350, 422, 469, 499, 422, 446, 322, 380, 361, 307, 380, 376, 409, 505, 442, 409, 365, 398, 442, 425, 497, 459, 376, 464, 477, 365, 483, 372, 483, 530, 630, 326, 272, 445, 302, 491, 380, 365, 328, 425, 270, 409, 361, 383, 530, 323, 398, 459, 322, 477, 499, 446, 464, 398, 409, 380, 383, 400, 409, 428, 445, 458, 294, 294, 483, 467, 499, 323, 400, 477, 555, 372, 270, 272, 458, 446, 505, 479, 530, 272, 422, 361, 520, 520, 497, 505, 451, 323, 491, 383, 428, 295, 272, 491, 361, 446, 529, 491, 505, 372, 611, 361, 439, 516, 372, 428, 381, 323, 470, 307, 458, 458, 372, 458, 458, 412, 380, 400, 422, 372, 307, 458, 409, 303, 458, 302, 459, 380, 446, 530, 376, 381, 361, 445, 328, 451, 294, 557, 451, 400, 451, 530, 307, 505, 383, 350, 328, 467, 380, 499, 361, 529, 412, 467, 428, 497, 294, 458, 446, 326, 307, 469, 381, 516, 425, 372, 383, 326, 611, 505, 470, 372, 534, 534, 477, 372, 425, 365, 272, 479, 458, 322, 361, 467, 630, 458, 458, 383, 516, 477, 458, 372, 307, 445, 303, 459, 380, 477, 409, 272, 350, 520, 516, 328, 383, 383, 400, 470, 425, 361, 400, 398, 380, 439, 307, 505, 302, 470, 469, 400, 380, 361, 322, 365, 497, 361, 372, 630, 469, 459, 458, 451, 458, 470, 467, 350, 516, 365, 380, 307, 376, 459, 381, 458, 400, 361, 445, 272, 445, 398, 361, 584, 372, 446, 557, 459, 361, 499, 534, 372, 326, 458, 398, 372, 412, 350, 459, 459, 272, 445, 380, 380, 361, 376, 409, 372, 422, 529, 505, 557, 326, 398, 422, 470, 557, 328, 302, 445, 422, 516]\n","Total number of videos:  886\n","Average frame per video: 422.21670428893907\n"]}]},{"cell_type":"code","source":["# to extract frame\n","def frame_extract(path):\n","  vidObj = cv2.VideoCapture(path)\n","  success = 1\n","  while success:\n","      success, image = vidObj.read()\n","      if success:\n","          yield image  # Returns frame"],"metadata":{"id":"2oh6i5_Qjyqc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install face_recognition\n","!mkdir '/content/drive/My Drive/preprocessedDataset'\n","!mkdir '/content/drive/My Drive/preprocessedDataset/fake'\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5VrDT6USjz56","executionInfo":{"status":"ok","timestamp":1740212928762,"user_tz":-330,"elapsed":26162,"user":{"displayName":"Anousha","userId":"04476830509364725369"}},"outputId":"1a6e037d-30b7-441d-8416-f22c378d1fcc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting face_recognition\n","  Downloading face_recognition-1.3.0-py2.py3-none-any.whl.metadata (21 kB)\n","Collecting face-recognition-models>=0.3.0 (from face_recognition)\n","  Downloading face_recognition_models-0.3.0.tar.gz (100.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.1/100.1 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.11/dist-packages (from face_recognition) (8.1.8)\n","Requirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.11/dist-packages (from face_recognition) (19.24.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from face_recognition) (1.26.4)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from face_recognition) (11.1.0)\n","Downloading face_recognition-1.3.0-py2.py3-none-any.whl (15 kB)\n","Building wheels for collected packages: face-recognition-models\n","  Building wheel for face-recognition-models (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for face-recognition-models: filename=face_recognition_models-0.3.0-py2.py3-none-any.whl size=100566162 sha256=481aa882a2f6f9b8760edcd477d8017cec4a7fddd43c208a21ccfd9a160dca69\n","  Stored in directory: /root/.cache/pip/wheels/04/52/ec/9355da79c29f160b038a20c784db2803c2f9fa2c8a462c176a\n","Successfully built face-recognition-models\n","Installing collected packages: face-recognition-models, face_recognition\n","Successfully installed face-recognition-models-0.3.0 face_recognition-1.3.0\n","mkdir: cannot create directory ‘/content/drive/My Drive/preprocessedDataset’: File exists\n","mkdir: cannot create directory ‘/content/drive/My Drive/preprocessedDataset/fake’: File exists\n"]}]},{"cell_type":"code","source":["import torch\n","import torchvision\n","# from torchvision import transforms\n","# from torch.utils.data import DataLoader\n","# from torch.utils.data.dataset import Dataset\n","import os\n","import numpy as np\n","import cv2\n","# import matplotlib.pyplot as plt\n","import face_recognition\n","from tqdm import tqdm\n","\n","# process the frames\n","def create_face_videos(path_list,out_dir):\n","\n","  # No. of video already preprocessed\n","  already_present_count = glob.glob(os.path.join(out_dir, '*.mp4'))\n","\n","  print(\"No of videos already present \" , len(already_present_count))\n","\n","  # Skip already preprocessed videos\n","  for path in tqdm(path_list):\n","    out_path = os.path.join(out_dir,path.split('/')[-1])\n","    file_exists = glob.glob(out_path)\n","\n","    if(len(file_exists) != 0):\n","      print(\"File Already exists: \" , out_path)\n","      continue\n","\n","    frames = []\n","    flag = 0\n","    face_all = []\n","    frames1 = []\n","\n","    # Video writer object to convert frames to video\n","    out = cv2.VideoWriter(out_path,cv2.VideoWriter_fourcc('M','J','P','G'), 30, (112,112))\n","\n","    for idx,frame in enumerate(frame_extract(path)):\n","      if(idx <= 150):\n","        frames.append(frame)\n","        if(len(frames) == 4):\n","          faces = face_recognition.face_locations(frame, model='hog')\n","\n","          for i,face in enumerate(faces):\n","            if face:\n","              top,right,bottom,left = face\n","            try:\n","              out.write(cv2.resize(frames[i][top:bottom,left:right,:],(112,112)))\n","            except:\n","              pass\n","\n","          frames = []\n","    try:\n","      del top,right,bottom,left\n","    except:\n","      pass\n","\n","    out.release()\n","\n","print(\"Data preprocessed!\")"],"metadata":{"id":"V1aTalOqiMfw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1740214226081,"user_tz":-330,"elapsed":8,"user":{"displayName":"Anousha","userId":"04476830509364725369"}},"outputId":"3b0327c9-4be7-48b6-d251-797350432317"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Data preprocessed!\n"]}]},{"cell_type":"code","source":["create_face_videos(video_files,'/content/drive/My Drive/preprocessedDataset/fake')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SVIVruN5w8d_","executionInfo":{"status":"ok","timestamp":1740221664034,"user_tz":-330,"elapsed":7381861,"user":{"displayName":"Anousha","userId":"04476830509364725369"}},"outputId":"566f9a43-9190-4f43-cdbb-1bf37565e684"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["No of videos already present  1\n"]},{"output_type":"stream","name":"stderr","text":["  0%|          | 2/886 [00:16<2:08:41,  8.73s/it]"]},{"output_type":"stream","name":"stdout","text":["File Already exists:  /content/drive/My Drive/preprocessedDataset/fake/id4_id23_0006.mp4\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 886/886 [2:03:01<00:00,  8.33s/it]\n"]}]}]}